{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7395990,"sourceType":"datasetVersion","datasetId":4300143}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:49:15.115418Z","iopub.status.idle":"2024-01-13T14:49:15.115798Z","shell.execute_reply.started":"2024-01-13T14:49:15.115597Z","shell.execute_reply":"2024-01-13T14:49:15.115612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_x = torch.load(\"\")\ndataset_y = torch.load(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtr, xts, ytr, yts = train_test_split(dataset_x, dataset_y, test_size=0.2, shuffle=True, stratify=dataset_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import *\nmy_dataset = torch.utils.data.TensorDataset(xtr,ytr) # create your datset\nmy_dataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32,\n                                          shuffle=True, num_workers=2)\n\nmy_dataset = torch.utils.data.TensorDataset(xts,yts) # create your datset\nmy_tdataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T14:49:15.117467Z","iopub.status.idle":"2024-01-13T14:49:15.117907Z","shell.execute_reply.started":"2024-01-13T14:49:15.117679Z","shell.execute_reply":"2024-01-13T14:49:15.117701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nfrom tempfile import TemporaryDirectory\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nimport torch\nimport torchvision.models as models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n\n\n\nimport timm\n\n# from timm\npretrained_model_name = \"resnet50\"\nmodel = timm.create_model(pretrained_model_name, pretrained=True)\n\nnum_channels = 1  # for grayscale images, but it could be any number\n# Extract the first conv layer's parameters\nnum_filters = model.conv1.out_channels\nkernel_size = model.conv1.kernel_size\nstride = model.conv1.stride\npadding = model.conv1.padding\nconv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\noriginal_weights = model.conv1.weight.data.mean(dim=1, keepdim=True)\nconv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\nmodel.conv1 = conv1\nmodel_ft = model\n\n# Freeze only the convolutional layers of the pre-trained model\nfor param in model_ft.parameters():\n    if isinstance(param, nn.Conv2d):\n        param.requires_grad = False\n\n\n\n# Modify the model head for fine-tuning\nnum_features = 2048\n\n# Additional linear layer and dropout layer\nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n    nn.Dropout(0.5),               # Dropout layer with 50% probability\n    nn.Linear(256, 4)    # Final prediction fc layer\n)\n\nmodel_ft = torch.nn.DataParallel(model_ft, device_ids = [0,1]).to(device)\n#model_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\n\n\nbatch_size=128\nnum_epochs=10\nval_size = len(my_tdataloader)\ntrain_size = len(my_dataloader) \n\nlosses = [] \naccuracies = [] \nval_losses = [] \nval_accuracies = [] \n# Train the model \n\nx = range(0,num_epochs)\nfor epoch in x: \n\tfor i, (images, labels) in enumerate(my_dataloader): \n\t\t# Forward pass \n\t\timages=images.to(device) \n\t\tlabels=labels.type(torch.LongTensor).to(device) \n\t\toutputs = model(images) \n\t\tloss = criterion(outputs, labels) \n\t\t\n\t\t# Backward pass and optimization \n\t\toptimizer.zero_grad() \n\t\tloss.backward() \n\t\toptimizer.step() \n\n\t\t_, predicted = torch.max(outputs.data, 1) \n\tacc = (predicted == labels).sum().item() / labels.size(0) \n\taccuracies.append(acc) \n\tlosses.append(loss.item()) \n\t\t\n\t# Evaluate the model on the validation set \n\tval_loss = 0.0\n\tval_acc = 0.0\n\twith torch.no_grad(): \n\t\tfor images, labels in my_tdataloader: \n\t\t\tlabels=labels.to(device) \n\t\t\timages=images.type(torch.LongTensor).to(device) \n\t\t\toutputs = model(images) \n\t\t\tloss = criterion(outputs, labels) \n\t\t\tval_loss += loss.item() \n\t\t\t\n\t\t\t_, predicted = torch.max(outputs.data, 1) \n\t\ttotal = labels.size(0) \n\t\tcorrect = (predicted == labels).sum().item() \n\t\tval_acc += correct / total \n\t\tval_accuracies.append(acc) \n\t\tval_losses.append(loss.item()) \n\t\n\t\t\t\n\tprint('Epoch [{}/{}],Loss:{:.4f},Validation Loss:{:.4f},Accuracy:{:.2f},Validation Accuracy:{:.2f}'.format( \n\t\tepoch+1, num_epochs, loss.item(), val_loss, acc ,val_acc))\n\n\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]}]}