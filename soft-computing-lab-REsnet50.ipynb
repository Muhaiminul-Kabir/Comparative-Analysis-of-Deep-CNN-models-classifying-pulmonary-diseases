{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:26:28.129483Z","iopub.status.busy":"2024-01-14T03:26:28.129139Z","iopub.status.idle":"2024-01-14T03:26:28.133685Z","shell.execute_reply":"2024-01-14T03:26:28.132764Z","shell.execute_reply.started":"2024-01-14T03:26:28.129454Z"},"trusted":true},"outputs":[],"source":["from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:26:55.453369Z","iopub.status.busy":"2024-01-14T03:26:55.453038Z","iopub.status.idle":"2024-01-14T03:27:35.525487Z","shell.execute_reply":"2024-01-14T03:27:35.524467Z","shell.execute_reply.started":"2024-01-14T03:26:55.453345Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","from torch import *\n","dataset_x = torch.load(\"/kaggle/input/combined-dataset-of-grayscale-cxr-images/dataset_x.pt\")\n","dataset_y = torch.load(\"/kaggle/input/combined-dataset-of-grayscale-cxr-images/dataset_y.pt\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:27:50.775240Z","iopub.status.busy":"2024-01-14T03:27:50.774404Z","iopub.status.idle":"2024-01-14T03:27:52.658617Z","shell.execute_reply":"2024-01-14T03:27:52.657627Z","shell.execute_reply.started":"2024-01-14T03:27:50.775207Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","xtr, xts, ytr, yts = train_test_split(dataset_x, dataset_y, test_size=0.2, shuffle=True, stratify=dataset_y)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:28:30.526602Z","iopub.status.busy":"2024-01-14T03:28:30.525992Z","iopub.status.idle":"2024-01-14T03:28:30.532532Z","shell.execute_reply":"2024-01-14T03:28:30.531497Z","shell.execute_reply.started":"2024-01-14T03:28:30.526567Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([5446, 1, 224, 224])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["xts.shape"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:48:54.351625Z","iopub.status.busy":"2024-01-14T03:48:54.351250Z","iopub.status.idle":"2024-01-14T03:48:54.358720Z","shell.execute_reply":"2024-01-14T03:48:54.357880Z","shell.execute_reply.started":"2024-01-14T03:48:54.351583Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import *\n","my_dataset = torch.utils.data.TensorDataset(xtr,ytr) # create your datset\n","my_dataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32,\n","                                          shuffle=True, num_workers=2)\n","\n","my_dataset = torch.utils.data.TensorDataset(xts,yts) # create your datset\n","my_tdataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-14T03:49:10.896222Z","iopub.status.busy":"2024-01-14T03:49:10.895858Z","iopub.status.idle":"2024-01-14T03:54:13.653468Z","shell.execute_reply":"2024-01-14T03:54:13.652062Z","shell.execute_reply.started":"2024-01-14T03:49:10.896195Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_26/315989530.py:81: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n","  x = range(0,num_epochs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1.0/20],Loss:1.3075,Accuracy:0.41\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m x: \n\u001b[1;32m     83\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(my_dataloader): \n\u001b[1;32m     84\u001b[0m \t\t\u001b[38;5;66;03m# Forward pass \u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \t\timages\u001b[38;5;241m=\u001b[39m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     86\u001b[0m \t\tlabels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m     87\u001b[0m \t\toutputs \u001b[38;5;241m=\u001b[39m model(images) \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import time\n","from tempfile import TemporaryDirectory\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","import torch\n","import torchvision.models as models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","\n","\n","\n","import timm\n","\n","# from timm\n","pretrained_model_name = \"resnet50\"\n","model = timm.create_model(pretrained_model_name, pretrained=True)\n","\n","num_channels = 1  # for grayscale images, but it could be any number\n","# Extract the first conv layer's parameters\n","num_filters = model.conv1.out_channels\n","kernel_size = model.conv1.kernel_size\n","stride = model.conv1.stride\n","padding = model.conv1.padding\n","conv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\n","original_weights = model.conv1.weight.data.mean(dim=1, keepdim=True)\n","conv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\n","model.conv1 = conv1\n","\n","\n","# Freeze only the convolutional layers of the pre-trained model\n","for param in model.parameters():\n","    if isinstance(param, nn.Conv2d):\n","        param.requires_grad = False\n","\n","\n","\n","# Modify the model head for fine-tuning\n","num_features = 2048\n","\n","# Additional linear layer and dropout layer\n","model.fc = nn.Sequential(\n","    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n","    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n","    nn.Dropout(0.5),               # Dropout layer with 50% probability\n","    nn.Linear(256, 4)    # Final prediction fc layer\n",")\n","\n","model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n","#model_ft = model_ft.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n","\n","\n","\n","batch_size=32\n","num_epochs=20\n","val_size = len(my_tdataloader)\n","train_size = len(my_dataloader) \n","\n","losses = [] \n","accuracies = [] \n","val_losses = [] \n","val_accuracies = [] \n","# Train the model \n","\n","x = range(0,num_epochs)\n","for epoch in x: \n","\tfor i, (images, labels) in enumerate(my_dataloader): \n","\t\t# Forward pass \n","\t\timages=images.to(device) \n","\t\tlabels=labels.type(torch.LongTensor).to(device) \n","\t\toutputs = model(images) \n","\t\tloss = criterion(outputs, labels) \n","\t\t\n","\t\t# Backward pass and optimization \n","\t\toptimizer_ft.zero_grad() \n","\t\tloss.backward() \n","\t\toptimizer_ft.step() \n","\n","\t\t_, predicted = torch.max(outputs.data, 1) \n","\tacc = (predicted == labels).sum().item() / labels.size(0) \n","\taccuracies.append(acc) \n","\tlosses.append(loss.item()) \n","\n","\t# Evaluate the model on the validation set\t\n","\tprint('Epoch [{}/{}],Loss:{:.4f},Accuracy:{:.2f}'.format( \n","\t\tepoch+1, num_epochs, loss.item(),acc))\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4300143,"sourceId":7395990,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
