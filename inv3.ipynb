{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:28:05.338360Z","iopub.status.busy":"2024-01-27T07:28:05.337966Z","iopub.status.idle":"2024-01-27T07:28:05.860376Z","shell.execute_reply":"2024-01-27T07:28:05.859530Z","shell.execute_reply.started":"2024-01-27T07:28:05.338329Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:28:05.862191Z","iopub.status.busy":"2024-01-27T07:28:05.861900Z","iopub.status.idle":"2024-01-27T07:29:29.636785Z","shell.execute_reply":"2024-01-27T07:29:29.635931Z","shell.execute_reply.started":"2024-01-27T07:28:05.862166Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","from torch import *\n","dataset_x = torch.load(\"/kaggle/input/zip-40k-dataset-cxr/final_x/final_x.pt\")\n","dataset_y = torch.load(\"/kaggle/input/zip-40k-dataset-cxr/final_y (1).pt\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:29.638369Z","iopub.status.busy":"2024-01-27T07:29:29.637955Z","iopub.status.idle":"2024-01-27T07:29:32.382182Z","shell.execute_reply":"2024-01-27T07:29:32.381376Z","shell.execute_reply.started":"2024-01-27T07:29:29.638344Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","xtr, xts, ytr, yts = train_test_split(dataset_x, dataset_y, test_size=0.2, shuffle=True, stratify=dataset_y)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.385577Z","iopub.status.busy":"2024-01-27T07:29:32.384839Z","iopub.status.idle":"2024-01-27T07:29:32.393978Z","shell.execute_reply":"2024-01-27T07:29:32.393184Z","shell.execute_reply.started":"2024-01-27T07:29:32.385540Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([32301, 1, 224, 224])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["xtr.size()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.395325Z","iopub.status.busy":"2024-01-27T07:29:32.395051Z","iopub.status.idle":"2024-01-27T07:29:32.405560Z","shell.execute_reply":"2024-01-27T07:29:32.404743Z","shell.execute_reply.started":"2024-01-27T07:29:32.395303Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([8076, 1, 224, 224])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["xts.size()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.406977Z","iopub.status.busy":"2024-01-27T07:29:32.406748Z","iopub.status.idle":"2024-01-27T07:29:32.415868Z","shell.execute_reply":"2024-01-27T07:29:32.415155Z","shell.execute_reply.started":"2024-01-27T07:29:32.406956Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import *\n","my_dataset = torch.utils.data.TensorDataset(xtr,ytr) # create your datset\n","my_dataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32,\n","                                          shuffle=True, num_workers=2)\n","\n","my_dataset = torch.utils.data.TensorDataset(xts,yts) # create your datset\n","my_tdataloader = torch.utils.data.DataLoader(my_dataset,batch_size=32)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.416987Z","iopub.status.busy":"2024-01-27T07:29:32.416768Z","iopub.status.idle":"2024-01-27T07:29:32.427415Z","shell.execute_reply":"2024-01-27T07:29:32.426601Z","shell.execute_reply.started":"2024-01-27T07:29:32.416967Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1010"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(my_dataloader)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.428986Z","iopub.status.busy":"2024-01-27T07:29:32.428604Z","iopub.status.idle":"2024-01-27T07:29:32.435557Z","shell.execute_reply":"2024-01-27T07:29:32.434749Z","shell.execute_reply.started":"2024-01-27T07:29:32.428955Z"},"trusted":true},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:29:32.437015Z","iopub.status.busy":"2024-01-27T07:29:32.436684Z","iopub.status.idle":"2024-01-27T07:29:32.447784Z","shell.execute_reply":"2024-01-27T07:29:32.446960Z","shell.execute_reply.started":"2024-01-27T07:29:32.436984Z"},"trusted":true},"outputs":[],"source":["rep = []"]},{"cell_type":"markdown","metadata":{},"source":["# model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T07:33:29.286507Z","iopub.status.busy":"2024-01-27T07:33:29.286116Z","iopub.status.idle":"2024-01-27T07:33:41.268435Z","shell.execute_reply":"2024-01-27T07:33:41.267077Z","shell.execute_reply.started":"2024-01-27T07:33:29.286476Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(my_dataloader): \n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Forward pass \u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     images\u001b[38;5;241m=\u001b[39m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     89\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images) \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import time\n","from tempfile import TemporaryDirectory\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","import torch\n","import torchvision.models as models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","\n","\n","\n","import timm\n","\n","# from timm\n","pretrained_model_name = \"inception_v3\"\n","model = timm.create_model(pretrained_model_name, pretrained=True)\n","print(model)\n","num_channels = 1  # for grayscale images, but it could be any number\n","# Extract the first conv layer's parameters\n","num_filters = model.Conv2d_1a_3x3.conv.out_channels\n","kernel_size = model.Conv2d_1a_3x3.conv.kernel_size\n","stride = model.Conv2d_1a_3x3.conv.stride\n","padding = model.Conv2d_1a_3x3.conv.padding\n","conv1 = torch.nn.Conv2d(num_channels, num_filters, kernel_size=kernel_size, stride=stride, padding=padding)\n","original_weights = model.Conv2d_1a_3x3.conv.weight.data.mean(dim=1, keepdim=True)\n","conv1.weight.data = original_weights.repeat(1, num_channels, 1, 1)\n","model.Conv2d_1a_3x3.conv = conv1\n","\n","\n","\n","# Freeze only the convolutional layers of the pre-trained model\n","for param in model.parameters():\n","    if isinstance(param, nn.Conv2d):\n","        param.requires_grad = False\n","\n","\n","\n","# Modify the model head for fine-tuning\n","num_features = 2048\n","\n","# Additional linear layer and dropout layer\n","model.fc = nn.Sequential(\n","    nn.Linear(num_features, 256),  # Additional linear layer with 256 output features\n","    nn.ReLU(inplace=True),         # Activation function (you can choose other activation functions too)\n","    nn.Dropout(0.5),               # Dropout layer with 50% probability\n","    nn.Linear(256, 4),    # Final prediction fc layer\n","    nn.Softmax()\n",")\n","\n","model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n","\n","\n","\n","batch_size=32\n","num_epochs=30\n","val_size = len(my_tdataloader)\n","train_size = len(my_dataloader) \n","\n","losses = [] \n","accuracies = [] \n","val_losses = [] \n","val_accuracies = [] \n","# Train the model \n","cnt = 0\n","x = range(0,num_epochs)\n","for epoch in x: \n","    cnt = 0\n","    for i, (images, labels) in enumerate(my_dataloader): \n","        # Forward pass \n","        images=images.to(device) \n","        labels=labels.type(torch.LongTensor).to(device) \n","        outputs = model(images) \n","        loss = criterion(outputs, labels) \n","        \n","        # Backward pass and optimization \n","        optimizer_ft.zero_grad() \n","        loss.backward() \n","        optimizer_ft.step() \n","        cnt = cnt+1\n","        print(cnt)\n","        clear_output()\n","        _, predicted = torch.max(outputs.data, 1)\n","        \n","    acc = (predicted == labels).sum().item() / labels.size(0) \n","    accuracies.append(acc) \n","    losses.append(loss.item()) \n","\n","    # Evaluate the model on the validation set\t\n","    rep.append('Epoch [{}/{}],Loss:{:.4f},Accuracy:{:.2f}'.format( \n","        epoch+1, num_epochs, loss.item(),acc))\n","    print('Epoch [{}/{}],Loss:{:.4f},Accuracy:{:.2f}'.format( \n","        epoch+1, num_epochs, loss.item(),acc))\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-27T07:29:35.674412Z","iopub.status.idle":"2024-01-27T07:29:35.674767Z","shell.execute_reply":"2024-01-27T07:29:35.674613Z","shell.execute_reply.started":"2024-01-27T07:29:35.674596Z"},"trusted":true},"outputs":[],"source":["rep"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-27T07:29:35.675759Z","iopub.status.idle":"2024-01-27T07:29:35.676204Z","shell.execute_reply":"2024-01-27T07:29:35.675991Z","shell.execute_reply.started":"2024-01-27T07:29:35.675970Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","import pandas as pd\n","\n","y_pred = []\n","y_true = []  \n","\n","# iterate over test data\n","for inputs, labels in my_tdataloader:\n","        output = model(inputs) # Feed Network\n","\n","        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n","        y_pred.extend(output) # Save Prediction\n","        \n","        labels = labels.data.cpu().numpy()\n","        y_true.extend(labels) # Save Truth\n","\n","# constant for classes\n","classes = ('COVID','Normal','Pneumonia','Bacterial infection')\n","\n","# Build confusion matrix\n","cf_matrix = confusion_matrix(y_true, y_pred)\n","df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n","                     columns = [i for i in classes])\n","plt.figure(figsize = (12,7))\n","sn.heatmap(df_cm, annot=True)\n","plt.savefig('output.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-01-27T07:29:35.678264Z","iopub.status.idle":"2024-01-27T07:29:35.678592Z","shell.execute_reply":"2024-01-27T07:29:35.678447Z","shell.execute_reply.started":"2024-01-27T07:29:35.678432Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_true, y_pred))\n","classification_report(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1074124,"sourceId":1808010,"sourceType":"datasetVersion"},{"datasetId":1796217,"sourceId":3167972,"sourceType":"datasetVersion"},{"datasetId":2024507,"sourceId":3355768,"sourceType":"datasetVersion"},{"datasetId":3057430,"sourceId":6370358,"sourceType":"datasetVersion"},{"datasetId":4300143,"sourceId":7456318,"sourceType":"datasetVersion"},{"datasetId":4340387,"sourceId":7483333,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
